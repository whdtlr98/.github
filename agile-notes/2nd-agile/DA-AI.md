# DA-AI
<details>
  <summary><h2>📜 광고성 리뷰 추출 & 제거</h2></summary>

### <mark>🎯 목적</mark>

**신뢰할 수 있는 정보 제공**

> SeoulPOT은 실제 방문자들이 작성한 리뷰를 통해 각 가게에 대한 진정한 평판을 반영하고자 함
> 
> 이를 통해 사용자는 보다 신뢰할 수 있는 정보에 기반하여 공간을 선택할 수 있음

<br/>

### <mark>💾 데이터</mark>
**약 2,000,000개의 사용자 공간 리뷰 데이터**

<br/>

### <mark>📃 과정</mark>

**① 리뷰 데이터 준비**

> 20자 이상, SENTIMENT_PARAM(0.5) 이상 데이터 준비 (Unlabeled)

**② 공간별 이상치 리뷰 추출**

> 이전 30일간의 일일 리뷰 수 평균 / 표준편차 계산
> 
> [평균 + OUTLIER_PARAM(2)* 표준편차]
> 
> 위 threshold를 기반으로 이 이상의 일일 리뷰 개수가 나올 경우 이상치 리뷰로 선정

**③ 공간별 이상치 리뷰들간의 유사 리뷰 추출**

> 가게+주소 조합당 tf-idf 벡터의 cosine유사도 계산
> 
> SIMILARITY_PARAM(0.5) 이상의 cosine 유사도를 가진 리뷰들 추출 (Labeling)

<br/>

### <mark>❓ 파라미터 선정 이유</mark>

**SENTIMENT_PARAM(0.5)** : 광고와 걸맞지 않은 가게의 공통된 단점을 걸러냄

**OUTLIER_PARAM(2)** : 기본 이상치 연산시 사용되는 가중치

**SIMILARITY_PARAM(0.5)** : 어순이 바뀌어도 맥락이 비슷한 리뷰를 찾기 위한 값

<br/>

### <mark>⚠️ 문제점</mark>

데이터 약 2,000,000개 중 약 1,400개 추출됨 (0.0007%) → 추가 판단 및 보완 필요

다른 요인으로 인해 리뷰가 많아진 경우도 검토 필요

</details>
<details>
  <summary><h2>🎭 사용자 리뷰 감정분석</summary>

### <mark>🎯 목적</mark>

**공간 평판 파악**

> 리뷰에 담긴 긍정적 및 부정적 피드백은 사용자 선호도를 직접적으로 반영하므로, 분석을 통해 공간의 평판을 파악할 수 있음

**방문 결정 지원**

> 명확한 긍정/부정 평가 시스템을 통해 공간 선택에 대한 자신감을 얻고, 만족도 높은 방문 경험을 할 수 있도록 도움

<br/>

### <mark>💾 데이터</mark>
**약 2,000,000개의 사용자 공간 리뷰 데이터**

<br/>

### <mark>📃 과정</mark>

**① 평가용 데이터셋 구축**

> 평가용 데이터셋 구축 (Human Eval 데이터 라벨링) 
> 
> 리뷰수 3000개 이상 보유 가게 20개 추출 (각기 다른 태그의 가게)
> 
> 리뷰 길이별 개수 비율에 맞추어 가게당 약 200개 랜덤샘플링 (Unlabeled)
> 
> Human Eval 데이터 라벨링 (긍정/부정)
> 
> 라벨링된 데이터들 중 리뷰 길이별 개수 비율에 맞추어 긍정 100개, 부정 100개 리샘플링

**② 학습 데이터 라벨링**

> Mistral-7B-Instruct-v0.1-GGUF (LLM Eval) 데이터 라벨링 수행
> 
> 리뷰수 3000개 이상 보유 가게 20개 추출 (Unlabeled)
> 
> 리뷰 길이별 개수 비율에 맞추어 여러 가게에 걸쳐 약 4300개 데이터 라벨링

**③ 사전학습모델 전이학습**

> labed dataset을 활용하여 전이학습 수행 (약 3500개)
> 
> KoELECTRA 모델에 대해 수행

**④ Labeling**

> 전이학습된 KoElectra를 활용하여 200,000,000개 데이터(Unlabeled) 라벨링 수행
> 
> POS_PARAM(0.9) 이상 긍정, NEG_PARAM(0.1) 이하 부정으로 판단

<br/>

### <mark>❓ 파라미터 선정 이유</mark>
<details>
    <summary>왜 Mistral-7B-Instruct-v0.1-GGUF으로 모든 데이터를 라벨링하지 않을까?</summary>

    다양한 Sentiment Analysis Pre-trained Model:
    - 평균 AUC: 0.7
    - inference 시간: 1초 이내

    LLM을 활용한 Sentiment Analysis:
    - AUC: 0.99
    - inference 시간: 약 120초 (200,000,000개 데이터 셋에 부적합)

    ➡️ LLM을 통해 학습용 데이터 라벨링을 수행한 후 해당 데이터로 사전학습 모델에 전이학습함으로써 모델의 무게와 소요 시간을 줄이자
</details>

<details>
    <summary>왜 KoELECTRA로 모델을 선택했을까?</summary>

    KoBERT:
    - AUC: 0.49 → 0.95
    - inference 시간: 약 0.5초

    KoELECTRA:
    - AUC: 0.50 → 0.98
    - inference 시간: 약 0.2초

    ➡️ 성능이 좋고 시간이 2배 이상 차이 나는 KoELECTRA를 활용하자
</details>


**POS_PARAM(0.9)** : NEG와 대칭으로 맞춤

**NEG_PARAM(0.1)** : FP의 경우 해당 결과로 인해 해당 장소의 평판을 낮출 수 있음 → 주의하여 확실한 부정 리뷰만을 라벨링

<br/>

### <mark>⚠️ 문제점</mark>

POS_PARAM, NEG_PARAM의 타당성 검토 필요 

</details>

<details>
  <summary><h2>📚 공간 테마 분류</summary>


### <mark>🎯 목적</mark>

사용자가 서울을 관광하기 원하는 형태, 목적에 따라 공간을 추천하자! 
가장 일반적으로 수요가 있는 관광 테마를 고려하여 '가족, 연인, 혼놀, 인테리어, 반려동물, 로컬애용, 트렌드, 힐링, 가성비' 이와 같은 9개의 테마를 선정함.

<br/>

### <mark>💾 데이터</mark>
**약 2,000,000개의 사용자 공간 리뷰 데이터**, 
**약 1300,000개의 공간 데이터**

<br/>

### <mark>📃 과정</mark>

**① 리뷰 데이터 준비**

> SENTIMENT 라벨링 리뷰 데이터 준비, 가게 태그 데이터 준비

**② 테마 키워드 정의**

> 해당 테마를 대표하는 키워드를 사전 형식으로 정의하여 리뷰에서 세어진 단어 빈도수로 가게의 테마를 분류하고자 한다.
>
> 예)
> "가족": ["가족", "아이", "부모님", "어린이", "유아", "가족모임", "가족 외식", "아이와 가기 좋아요", "대화하기 좋아요", "주차하기 편해요","친척·형제", "어머님", "아버님"]
> 
> 

**③ 가중치 계산**

> keyword_weights - 네이버 키워드 태그 선택 인원수 추출
>
> tfidf_weights - TF-IDF 통해 빈도수 처리
>
> length_weight - 길이가 길수록 리뷰의 정확도가 올라가므로 가중치 높게 처리
>
> 

**② 가중치 적용 및 테마 분류**
> 가게 평균의 감정 점수가 0.9 이상(긍정)인 것들만 테마 분류에 포함
>
> 위에서 정한 가중치들 곱으로 카테고리별 가중치 계산
>
> 전체 리뷰 합쳐서 가게 당 테마의 최종 가중치 계산 및 해당 가게의 테마 비율(30-80% 사이만 테마 분류 라벨링) 계산
>
> 


<br/>

### <mark>❓ 파라미터 선정 이유</mark>

**keyword_weights(>5)** : 리뷰가 적은 가게들의 비율 불균형 방지를 위해 5개 이하의 키워드는 무시

**테마 비율(30-80)** : 가게가 테마를 대표하는지 판단하기 위해 쓰이는 파라미터

**SIMILARITY_PARAM(0.9)** : 해당 서비스는 테마에 맞는 공간 '추천' 서비스로 긍정을 나타내는 가게를 뽑기 위함

<br/>

### <mark>⚠️ 문제점</mark>

1. 상대적 비율의 파라미터로 판단하다 보니 리뷰가 적어 테마 판단이 불가능한 가게 또한 분류됨

2. 분류되는 데이터가 매우 적음 (13만개 중 1500개)

3. 흔히 찾는 테마에 정보가 집중됨(연인,가족)

4. 시간 단축 상 TF-IDF 자체를 긍정의 리뷰들만 계산하게 했는데 분류 정확도 개선 필요


</details>
